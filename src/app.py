#!/usr/bin/env python3
"""
app.py - Flask web application for arXiv combinatorics frontend

Main web interface for browsing arXiv papers.
"""

from flask import Flask, render_template, request, jsonify, abort, redirect, url_for, Response
import pymysql
from config import DB_CONFIG, FLASK_CONFIG, FETCH_SECRET, validate_config
from datetime import datetime, date
import calendar
import re
from utils import strip_accents, slugify

# Validate configuration on startup
validate_config()

app = Flask(__name__)
app.config.update(FLASK_CONFIG)

# Register slugify as a Jinja filter
app.jinja_env.filters['slugify'] = lambda name: slugify(name) if name else ''


def protect_capitals_for_bibtex(title):
    """
    Protect capital letters in a title for BibTeX by wrapping them in braces.
    This ensures BibTeX won't lowercase them. The very first character of the
    title is left unprotected (BibTeX preserves it regardless).

    Example: "A new formula for Macdonald polynomials using LLT polynomials"
          -> "A new formula for {M}acdonald polynomials using {LLT} polynomials"
    """
    if not title:
        return title

    def protect_match(match):
        return f"{{{match.group(0)}}}"

    # Protect the title after the first character (BibTeX keeps the first letter)
    first_char = title[0]
    rest = title[1:]

    # Protect sequences of 2+ capitals (acronyms: LLT, RNA, DNA, etc.)
    rest = re.sub(r'[A-Z]{2,}', protect_match, rest)

    # Protect remaining single capitals
    rest = re.sub(r'[A-Z]', protect_match, rest)

    return first_char + rest



def generate_bibtex_key(authors, year, published=False):
    """
    Generate BibTeX key from authors and year.

    Args:
        authors: List of author names
        year: Publication year
        published: If True, omit the 'x' suffix for published papers

    Returns:
        BibTeX key string (e.g., "SmithJones2024x" or "SmithJones2024")
    """
    suffix = '' if published else 'x'
    if authors:
        last_names = []
        for author in authors:
            last_name = author.split()[-1]
            last_name = strip_accents(last_name)
            last_name = ''.join(c for c in last_name if c.isalnum())
            last_names.append(last_name)
        return f"{''.join(last_names)}{year}{suffix}"
    else:
        return f"arxiv{year}{suffix}"


def arxiv2bib(paper_data):
    """
    Generate arXiv BibTeX entry from paper data.

    Args:
        paper_data: Dict with keys: arxiv_id, title, authors, published_date, journal_ref, doi

    Returns:
        BibTeX string
    """
    year = paper_data['published_date'].year if hasattr(paper_data['published_date'], 'year') else paper_data['published_date']
    bibtex_key = generate_bibtex_key(paper_data.get('authors', []), year, published=False)

    author_str = ' and '.join(paper_data.get('authors', [])) if paper_data.get('authors') else 'Unknown'

    clean_arxiv_id = re.sub(r'v\d+$', '', paper_data['arxiv_id'])

    protected_title = protect_capitals_for_bibtex(paper_data['title'])

    bibtex = f"""@article{{{bibtex_key},
Author = {{{author_str}}},
Title = {{{protected_title}}},
Year = {{{year}}},
Eprint = {{{clean_arxiv_id}}},
  url = {{https://arxiv.org/abs/{clean_arxiv_id}}},
journal = {{arXiv e-prints}}"""

    if paper_data.get('journal_ref'):
        bibtex += f",\njournalref = {{{paper_data['journal_ref']}}}"

    if paper_data.get('doi'):
        bibtex += f",\ndoi = {{{paper_data['doi']}}}"

    bibtex += "\n}"
    return bibtex


def doi2bib(doi, paper_data=None):
    """
    Generate BibTeX entry from DOI using content negotiation,
    or create a custom entry if paper_data is provided.

    Args:
        doi: DOI string
        paper_data: Optional dict with paper metadata for custom formatting

    Returns:
        BibTeX string or None on error
    """
    import requests

    if paper_data:
        # Generate custom BibTeX with user's preferred format
        year = paper_data['published_date'].year if hasattr(paper_data['published_date'], 'year') else paper_data['published_date']
        bibtex_key = generate_bibtex_key(paper_data.get('authors', []), year, published=True)

        author_str = ' and '.join(paper_data.get('authors', [])) if paper_data.get('authors') else 'Unknown'
        protected_title = protect_capitals_for_bibtex(paper_data['title'])

        bibtex = f"""@article{{{bibtex_key},
Author = {{{author_str}}},
Title = {{{protected_title}}},
Year = {{{year}}},
journal = {{{paper_data.get('journal_ref', '')}}},
doi = {{{doi}}},
  url = {{https://doi.org/{doi}}}
}}"""
        return bibtex
    else:
        # Fetch from DOI.org
        try:
            doi_url = f"https://doi.org/{doi}"
            headers = {'Accept': 'application/x-bibtex'}
            response = requests.get(doi_url, headers=headers, timeout=10)
            response.raise_for_status()
            return response.text
        except requests.RequestException:
            return None


def get_db_connection():
    """Create and return a database connection."""
    return pymysql.connect(**DB_CONFIG, cursorclass=pymysql.cursors.DictCursor)


def ensure_author_slugs():
    """Add slug column if missing and populate any NULL slugs."""
    conn = get_db_connection()
    cursor = conn.cursor()
    try:
        # Add slug column if it doesn't exist
        cursor.execute("SHOW COLUMNS FROM authors LIKE 'slug'")
        if not cursor.fetchone():
            cursor.execute("ALTER TABLE authors ADD COLUMN slug VARCHAR(255)")
            cursor.execute("CREATE INDEX idx_author_slug ON authors(slug)")
            conn.commit()

        # Populate missing slugs
        cursor.execute("SELECT id, name FROM authors WHERE slug IS NULL")
        authors = cursor.fetchall()
        if authors:
            for author in authors:
                cursor.execute("UPDATE authors SET slug = %s WHERE id = %s",
                               (slugify(author['name']), author['id']))
            conn.commit()
    finally:
        cursor.close()
        conn.close()


# Populate slugs on startup
try:
    ensure_author_slugs()
except Exception:
    pass  # DB may not be available during development


def get_paper_authors(cursor, paper_id):
    """Get ordered list of authors for a paper."""
    cursor.execute("""
        SELECT a.name
        FROM authors a
        JOIN paper_authors pa ON a.id = pa.author_id
        WHERE pa.paper_id = %s
        ORDER BY pa.author_order
    """, (paper_id,))
    return [row['name'] for row in cursor.fetchall()]


def attach_authors(cursor, papers):
    """Attach authors to a list of papers in a single query (avoids N+1)."""
    if not papers:
        return
    paper_ids = [p['id'] for p in papers]
    placeholders = ','.join(['%s'] * len(paper_ids))
    cursor.execute(f"""
        SELECT pa.paper_id, a.name
        FROM authors a
        JOIN paper_authors pa ON a.id = pa.author_id
        WHERE pa.paper_id IN ({placeholders})
        ORDER BY pa.paper_id, pa.author_order
    """, paper_ids)
    authors_by_paper = {}
    for row in cursor.fetchall():
        authors_by_paper.setdefault(row['paper_id'], []).append(row['name'])
    for paper in papers:
        paper['authors'] = authors_by_paper.get(paper['id'], [])


@app.route('/')
def index():
    """Homepage - list recent papers."""
    page = request.args.get('page', 1, type=int)
    per_page = 20
    offset = (page - 1) * per_page

    conn = get_db_connection()
    cursor = conn.cursor()

    # Get total count and author count
    cursor.execute("SELECT COUNT(*) as count FROM papers")
    total = cursor.fetchone()['count']

    cursor.execute("SELECT COUNT(*) as count FROM authors")
    total_authors = cursor.fetchone()['count']

    # Get latest published date
    cursor.execute("SELECT MAX(published_date) as latest FROM papers")
    latest_date = cursor.fetchone()['latest']

    # Get papers for current page
    cursor.execute("""
        SELECT id, arxiv_id, title, abstract, published_date, updated_date,
               journal_ref, doi, comment, primary_category
        FROM papers
        ORDER BY published_date DESC, id DESC
        LIMIT %s OFFSET %s
    """, (per_page, offset))

    papers = cursor.fetchall()

    attach_authors(cursor, papers)

    cursor.close()
    conn.close()

    total_pages = (total + per_page - 1) // per_page

    return render_template('index.html',
                         papers=papers,
                         page=page,
                         total_pages=total_pages,
                         total=total,
                         total_authors=total_authors,
                         latest_date=latest_date)


@app.route('/paper/<path:arxiv_id>')
def paper_detail(arxiv_id):
    """Paper detail page."""
    conn = get_db_connection()
    cursor = conn.cursor()

    cursor.execute("""
        SELECT id, arxiv_id, title, abstract, published_date, updated_date,
               comment, journal_ref, doi, primary_category
        FROM papers
        WHERE arxiv_id = %s
    """, (arxiv_id,))

    paper = cursor.fetchone()

    if not paper:
        abort(404)

    paper['authors'] = get_paper_authors(cursor, paper['id'])

    cursor.close()
    conn.close()

    return render_template('paper.html', paper=paper)


@app.route('/api/bibtex/<path:arxiv_id>')
def bibtex(arxiv_id):
    """Generate arXiv BibTeX entry for a paper."""
    conn = get_db_connection()
    cursor = conn.cursor()

    cursor.execute("""
        SELECT id, arxiv_id, title, published_date, journal_ref, doi
        FROM papers
        WHERE arxiv_id = %s
    """, (arxiv_id,))

    paper = cursor.fetchone()

    if not paper:
        abort(404)

    paper['authors'] = get_paper_authors(cursor, paper['id'])
    cursor.close()
    conn.close()

    bibtex = arxiv2bib(paper)
    return bibtex, 200, {'Content-Type': 'text/plain; charset=utf-8'}


@app.route('/api/doi-bibtex/<path:arxiv_id>')
def doi_bibtex(arxiv_id):
    """Generate published BibTeX entry for a paper with DOI."""
    conn = get_db_connection()
    cursor = conn.cursor()

    cursor.execute("""
        SELECT id, arxiv_id, title, published_date, journal_ref, doi
        FROM papers
        WHERE arxiv_id = %s
    """, (arxiv_id,))

    paper = cursor.fetchone()

    if not paper or not paper['doi']:
        abort(404)

    paper['authors'] = get_paper_authors(cursor, paper['id'])
    cursor.close()
    conn.close()

    # Generate custom BibTeX with user's preferred format
    bibtex = doi2bib(paper['doi'], paper)
    if bibtex:
        return bibtex, 200, {'Content-Type': 'text/plain; charset=utf-8'}
    else:
        return "Error generating DOI BibTeX", 500, {'Content-Type': 'text/plain; charset=utf-8'}


@app.route('/tools')
def tools():
    """Tools page for BibTeX generation."""
    return render_template('tools.html')


@app.route('/api/generate-bibtex', methods=['POST'])
def generate_bibtex_api():
    """API endpoint to generate BibTeX from arXiv ID or DOI."""
    data = request.get_json()
    input_text = data.get('input', '').strip()

    if not input_text:
        return jsonify({'error': 'Please provide an arXiv ID or DOI'}), 400

    # Try to parse as arXiv ID or URL
    arxiv_id = None
    doi = None

    # Check if it's an arXiv URL or ID
    if 'arxiv.org' in input_text.lower():
        # Extract ID from URL
        match = re.search(r'arxiv\.org/(?:abs|pdf)/([0-9]+\.[0-9]+(?:v[0-9]+)?)', input_text, re.IGNORECASE)
        if match:
            arxiv_id = match.group(1)
    elif re.match(r'^[0-9]+\.[0-9]+(?:v[0-9]+)?$', input_text):
        # Direct arXiv ID
        arxiv_id = input_text

    # Check if it's a DOI or DOI URL
    if not arxiv_id:
        if 'doi.org/' in input_text.lower():
            # Extract DOI from URL
            doi = input_text.split('doi.org/')[-1]
        elif re.match(r'^10\.\d+/', input_text):
            # Direct DOI
            doi = input_text

    if arxiv_id:
        # Fetch from our database
        conn = get_db_connection()
        cursor = conn.cursor()

        cursor.execute("""
            SELECT id, arxiv_id, title, published_date, journal_ref, doi
            FROM papers
            WHERE arxiv_id LIKE %s
        """, (f"{arxiv_id}%",))

        paper = cursor.fetchone()

        if paper:
            paper['authors'] = get_paper_authors(cursor, paper['id'])
            cursor.close()
            conn.close()

            arxiv_bib = arxiv2bib(paper)
            result = {'arxiv': arxiv_bib}

            if paper['doi']:
                published_bib = doi2bib(paper['doi'], paper)
                if published_bib:
                    result['published'] = published_bib

            return jsonify(result)
        else:
            cursor.close()
            conn.close()
            return jsonify({'error': 'arXiv paper not found in database'}), 404

    elif doi:
        # Fetch directly from DOI
        bibtex = doi2bib(doi)
        if bibtex:
            return jsonify({'published': bibtex})
        else:
            return jsonify({'error': 'Failed to fetch BibTeX from DOI'}), 500

    return jsonify({'error': 'Could not parse input as arXiv ID or DOI'}), 400


@app.route('/search')
def search():
    """Search papers by title or author."""
    query = request.args.get('q', '').strip()
    page = request.args.get('page', 1, type=int)
    per_page = 20
    offset = (page - 1) * per_page

    if not query:
        return render_template('search.html', papers=[], query='', total=0)

    conn = get_db_connection()
    cursor = conn.cursor()

    author_term = f"%{query}%"

    # Get latest published date
    cursor.execute("SELECT MAX(published_date) as latest FROM papers")
    latest_date = cursor.fetchone()['latest']

    # Use FULLTEXT for title/abstract when words are long enough (min 3 chars),
    # fall back to LIKE for very short queries
    words = query.split()
    use_fulltext = all(len(w) >= 3 for w in words) and len(words) > 0

    if use_fulltext:
        ft_query = '+' + ' +'.join(words)  # boolean mode: require all words

        cursor.execute("""
            SELECT COUNT(DISTINCT p.id) as count
            FROM papers p
            LEFT JOIN paper_authors pa ON p.id = pa.paper_id
            LEFT JOIN authors a ON pa.author_id = a.id
            WHERE MATCH(p.title, p.abstract) AGAINST(%s IN BOOLEAN MODE)
               OR a.name LIKE %s
        """, (ft_query, author_term))

        total = cursor.fetchone()['count']

        cursor.execute("""
            SELECT DISTINCT p.id, p.arxiv_id, p.title, p.abstract,
                   p.published_date, p.updated_date, p.journal_ref, p.doi,
                   p.comment, p.primary_category
            FROM papers p
            LEFT JOIN paper_authors pa ON p.id = pa.paper_id
            LEFT JOIN authors a ON pa.author_id = a.id
            WHERE MATCH(p.title, p.abstract) AGAINST(%s IN BOOLEAN MODE)
               OR a.name LIKE %s
            ORDER BY p.published_date DESC, p.id DESC
            LIMIT %s OFFSET %s
        """, (ft_query, author_term, per_page, offset))
    else:
        like_term = f"%{query}%"

        cursor.execute("""
            SELECT COUNT(DISTINCT p.id) as count
            FROM papers p
            LEFT JOIN paper_authors pa ON p.id = pa.paper_id
            LEFT JOIN authors a ON pa.author_id = a.id
            WHERE p.title LIKE %s
               OR p.abstract LIKE %s
               OR a.name LIKE %s
        """, (like_term, like_term, like_term))

        total = cursor.fetchone()['count']

        cursor.execute("""
            SELECT DISTINCT p.id, p.arxiv_id, p.title, p.abstract,
                   p.published_date, p.updated_date, p.journal_ref, p.doi,
                   p.comment, p.primary_category
            FROM papers p
            LEFT JOIN paper_authors pa ON p.id = pa.paper_id
            LEFT JOIN authors a ON pa.author_id = a.id
            WHERE p.title LIKE %s
               OR p.abstract LIKE %s
               OR a.name LIKE %s
            ORDER BY p.published_date DESC, p.id DESC
            LIMIT %s OFFSET %s
        """, (like_term, like_term, like_term, per_page, offset))

    papers = cursor.fetchall()

    attach_authors(cursor, papers)

    cursor.close()
    conn.close()

    total_pages = (total + per_page - 1) // per_page

    return render_template('search.html',
                         papers=papers,
                         query=query,
                         page=page,
                         total_pages=total_pages,
                         total=total,
                         latest_date=latest_date)


@app.route('/author/<author_slug>')
def author_papers(author_slug):
    """List all papers by a specific author (looked up by slug)."""
    page = request.args.get('page', 1, type=int)
    per_page = 20
    offset = (page - 1) * per_page

    conn = get_db_connection()
    cursor = conn.cursor()

    # Look up by slug first, fall back to name (for old-format URLs)
    cursor.execute("SELECT id, name, slug FROM authors WHERE slug = %s", (author_slug,))
    author = cursor.fetchone()
    if not author:
        # Fall back: try matching by exact name (old URLs with spaces)
        cursor.execute("SELECT id, name, slug FROM authors WHERE name = %s", (author_slug,))
        author = cursor.fetchone()
    if not author:
        abort(404)

    # Redirect old-format URLs to the slug URL
    if author.get('slug') and author_slug != author['slug']:
        return redirect(url_for('author_papers', author_slug=author['slug'], page=page), code=301)

    # Get latest published date
    cursor.execute("SELECT MAX(published_date) as latest FROM papers")
    latest_date = cursor.fetchone()['latest']

    # Get total count
    cursor.execute("""
        SELECT COUNT(*) as count
        FROM papers p
        JOIN paper_authors pa ON p.id = pa.paper_id
        WHERE pa.author_id = %s
    """, (author['id'],))
    total = cursor.fetchone()['count']

    # Get papers
    cursor.execute("""
        SELECT p.id, p.arxiv_id, p.title, p.abstract,
               p.published_date, p.updated_date, p.journal_ref, p.doi,
               p.comment, p.primary_category
        FROM papers p
        JOIN paper_authors pa ON p.id = pa.paper_id
        WHERE pa.author_id = %s
        ORDER BY p.published_date DESC, p.id DESC
        LIMIT %s OFFSET %s
    """, (author['id'], per_page, offset))

    papers = cursor.fetchall()

    attach_authors(cursor, papers)

    cursor.close()
    conn.close()

    total_pages = (total + per_page - 1) // per_page

    return render_template('author.html',
                         author=author,
                         papers=papers,
                         page=page,
                         total_pages=total_pages,
                         total=total,
                         latest_date=latest_date)


@app.route('/browse')
def browse_by_date():
    """Browse papers by calendar date."""
    year = request.args.get('year', datetime.now().year, type=int)

    conn = get_db_connection()
    cursor = conn.cursor()

    # Get paper counts by date for the year
    cursor.execute("""
        SELECT DATE(published_date) as date, COUNT(*) as count
        FROM papers
        WHERE YEAR(published_date) = %s
        GROUP BY DATE(published_date)
    """, (year,))

    date_counts = {row['date']: row['count'] for row in cursor.fetchall()}

    # Get available years with paper counts
    cursor.execute("""
        SELECT YEAR(published_date) as year, COUNT(*) as count
        FROM papers
        GROUP BY YEAR(published_date)
        ORDER BY year DESC
    """)
    available_years = [(row['year'], row['count']) for row in cursor.fetchall()]

    cursor.close()
    conn.close()

    # Build calendar data for each month
    month_data = []
    month_names = ['', 'January', 'February', 'March', 'April', 'May', 'June',
                   'July', 'August', 'September', 'October', 'November', 'December']

    for month in range(1, 13):
        cal = calendar.monthcalendar(year, month)
        days = []
        for week in cal:
            for day in week:
                if day == 0:
                    days.append({'day': 0, 'count': 0})
                else:
                    date_obj = date(year, month, day)
                    count = date_counts.get(date_obj, 0)
                    days.append({
                        'day': day,
                        'count': count,
                        'date_str': f"{year:04d}-{month:02d}-{day:02d}"
                    })

        month_data.append({
            'name': month_names[month],
            'days': days
        })

    return render_template('browse.html',
                         year=year,
                         month_data=month_data,
                         available_years=available_years)


@app.route('/date/<date_str>')
def papers_by_date(date_str):
    """Show papers from a specific date."""
    try:
        date = datetime.strptime(date_str, '%Y-%m-%d').date()
    except ValueError:
        abort(404)

    conn = get_db_connection()
    cursor = conn.cursor()

    cursor.execute("""
        SELECT id, arxiv_id, title, abstract, published_date, updated_date,
               journal_ref, doi, comment, primary_category
        FROM papers
        WHERE DATE(published_date) = %s
        ORDER BY id DESC
    """, (date,))

    papers = cursor.fetchall()

    attach_authors(cursor, papers)

    cursor.close()
    conn.close()

    return render_template('date.html',
                         date=date,
                         papers=papers)


@app.route('/random')
def random_paper():
    """Redirect to a random paper."""
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("SELECT arxiv_id FROM papers ORDER BY RAND() LIMIT 1")
    paper = cursor.fetchone()
    cursor.close()
    conn.close()
    if not paper:
        abort(404)
    return redirect(url_for('paper_detail', arxiv_id=paper['arxiv_id']))


@app.route('/api/author-bibtex/<author_slug>')
def author_bibtex(author_slug):
    """Generate BibTeX for all papers by an author."""
    conn = get_db_connection()
    cursor = conn.cursor()

    cursor.execute("SELECT id, name FROM authors WHERE slug = %s", (author_slug,))
    author = cursor.fetchone()
    if not author:
        cursor.execute("SELECT id, name FROM authors WHERE name = %s", (author_slug,))
        author = cursor.fetchone()
    if not author:
        abort(404)

    cursor.execute("""
        SELECT p.id, p.arxiv_id, p.title, p.published_date, p.journal_ref, p.doi
        FROM papers p
        JOIN paper_authors pa ON p.id = pa.paper_id
        WHERE pa.author_id = %s
        ORDER BY p.published_date DESC
    """, (author['id'],))

    papers = cursor.fetchall()
    attach_authors(cursor, papers)
    entries = []
    for paper in papers:
        # Always include arXiv entry
        entries.append(arxiv2bib(paper))
        # If published, also include the published entry
        if paper.get('doi'):
            pub_bib = doi2bib(paper['doi'], paper)
            if pub_bib:
                entries.append(pub_bib)

    cursor.close()
    conn.close()

    bibtex_all = '\n\n'.join(entries)
    return bibtex_all, 200, {'Content-Type': 'text/plain; charset=utf-8'}


@app.route('/fetch')
def fetch_papers():
    """Fetch recent papers from arXiv. Requires secret key."""
    key = request.args.get('key', '')
    days = request.args.get('days', 1, type=int)

    if not FETCH_SECRET or key != FETCH_SECRET:
        abort(403)

    # Cap days to prevent abuse
    days = min(days, 30)

    from fetch_arxiv import fetch_recent_papers
    import io, contextlib

    # Capture output from fetch function
    output = io.StringIO()
    with contextlib.redirect_stdout(output):
        fetch_recent_papers(days=days)

    return output.getvalue(), 200, {'Content-Type': 'text/plain; charset=utf-8'}


if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=True)
